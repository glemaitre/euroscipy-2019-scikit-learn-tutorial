{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "# Introduction to scikit-learn: basic preprocessing for basic model fitting\n",
    "\n",
    "In this lecture note, we will aim at introducing:\n",
    "* the difference between numerical and categorical variables;\n",
    "* the importance of scaling numerical variables;\n",
    "* the way to encode categorical variables;\n",
    "* combine different preprocessing on different type of data;\n",
    "* evaluate the performance of a model via cross-validation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduce the dataset\n",
    "\n",
    "To this aim, we will use data from the 1985 \"Current Population Survey\"\n",
    "(CPS). The goal with this data is to regress wages from heterogeneous data\n",
    "such as age, experience, education, family information, etc.\n",
    "\n",
    "Let's first load the data located in the `datasets` folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(os.path.join('datasets', 'cps_85_wages.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can quickly have a look at the head of the dataframe to check the type\n",
    "of available data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The target in our study will be the \"WAGE\" columns while we will use the\n",
    "other columns to fit a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "target_name = \"WAGE\"\n",
    "target = df[target_name].to_numpy()\n",
    "data = df.drop(columns=target_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check the number of samples and the number of features available in\n",
    "the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "print(\n",
    "    f\"The dataset contains {data.shape[0]} samples and {data.shape[1]} \"\n",
    "    \"features\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Work with numerical data\n",
    "\n",
    "The most intuitive type of data in machine learning which can (almost)\n",
    "directly be used in machine learning are known as numerical data. We can\n",
    "quickly have a look at such data by selecting the subset of columns from\n",
    "the original data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "print(data.columns)\n",
    "numerical_columns = ['AGE', 'EDUCATION', 'EXPERIENCE']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use this subset of data to fit linear regressor to infer the wage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "data_numeric = data[numerical_columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When building a machine learning model, it is important to leave out a\n",
    "subset of the data which we can use later to evaluate the trained model.\n",
    "The data used to fit a model a called training data while the one used to\n",
    "assess a model are called testing data.\n",
    "\n",
    "Scikit-learn provides an helper function `train_test_split` which will\n",
    "split the dataset into a training and a testing set. It will ensure that\n",
    "the data are shuffled before splitting the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data_train, data_test, target_train, target_test = train_test_split(\n",
    "    data_numeric, target, random_state=42\n",
    ")\n",
    "\n",
    "print(\n",
    "    f\"The training dataset contains {data_train.shape[0]} samples and \"\n",
    "    f\"{data_train.shape[1]} features\"\n",
    ")\n",
    "print(\n",
    "    f\"The testing dataset contains {data_test.shape[0]} samples and \"\n",
    "    f\"{data_test.shape[1]} features\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "We will build a Support Vector Machine (SVM) which is a linear model. The\n",
    "`fit` method is called to train the data and only the training data should\n",
    "be given for this purpose.\n",
    "To evaluate our model, we can use the method `score`. It will compute the\n",
    "coefficient of determination R2 when dealing with a regression problem.\n",
    "\n",
    "In addition, we checking the time required to train the model and internally\n",
    "check the number of iterations done by the solver to find a solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVR\n",
    "\n",
    "model = LinearSVR()\n",
    "start = time.time()\n",
    "model.fit(data_train, target_train)\n",
    "elapsed_time = time.time() - start\n",
    "print(\n",
    "    f\"The R2 score using a {model.__class__.__name__} is \"\n",
    "    f\"{model.score(data_test, target_test):.2f} with a fitting time of \"\n",
    "    f\"{elapsed_time:.3f} seconds in {model.n_iter_} iterations\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should not the `ConvergenceWarning` which inform us that our model stopped\n",
    "learning since it reaches the maximum number of iterations allowed by the\n",
    "user. This could potentially be detrimental for the model accuracy. We can\n",
    "follow the (bad) advice given in the warning message and increase the maximum\n",
    "number of iterations allowed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "model = LinearSVR(max_iter=50000)\n",
    "start = time.time()\n",
    "model.fit(data_train, target_train)\n",
    "elapsed_time = time.time() - start\n",
    "print(\n",
    "    f\"The R2 score using a {model.__class__.__name__} is \"\n",
    "    f\"{model.score(data_test, target_test):.2f} with a fitting time of \"\n",
    "    f\"{elapsed_time:.3f} seconds in {model.n_iter_} iterations\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can observe an increase in performance add the cost of a longer training.\n",
    "Instead of increasing the number of iterations, we could instead know a bit\n",
    "more about the SVR model and known that it is expecting input data to be\n",
    "scaled before to start training. A range of preprocessing algorithms in\n",
    "scikit-learn allows to transform the input data before to train a model.\n",
    "We can easily combine these sequential operation with a scikit-learn\n",
    "`Pipeline` which will chain the operations and can be used as any other\n",
    "classifier or regressor. The helper function `make_pipeline` will create\n",
    "a `Pipeline` by giving the successive transformations to perform.\n",
    "\n",
    "In our case, we will standardize the data and then train a linear SVR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "model = make_pipeline(StandardScaler(), LinearSVR())\n",
    "start = time.time()\n",
    "model.fit(data_train, target_train)\n",
    "elapsed_time = time.time() - start\n",
    "print(\n",
    "    f\"The R2 score using a {model.__class__.__name__} is \"\n",
    "    f\"{model.score(data_test, target_test):.2f} with a fitting time of \"\n",
    "    f\"{elapsed_time:.3f} seconds in {model[-1].n_iter_} iterations\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the training time and the number of iterations is much\n",
    "shorter while the accuracy is equivalent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "score = cross_val_score(model, data_numeric, target)\n",
    "print(f\"The R2 score is: {score.mean():.2f} +- {score.std():.2f}\")\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_columns = [\n",
    "    'SOUTH', 'SEX', 'UNION', 'RACE', 'OCCUPATION', 'SECTOR', 'MARR'\n",
    "]\n",
    "data_categorical = data[categorical_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "print(data_categorical.head())\n",
    "print(f\"The datasets is composed of {data_categorical.shape[1]} features\")\n",
    "encoder = OrdinalEncoder()\n",
    "data_encoded = encoder.fit_transform(data_categorical)\n",
    "\n",
    "print(f\"The dataset encoded contains {data_encoded.shape[1]} features\")\n",
    "print(data_encoded[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "print(data_categorical.head())\n",
    "print(f\"The datasets is composed of {data_categorical.shape[1]} features\")\n",
    "encoder = OneHotEncoder(sparse=False)\n",
    "data_encoded = encoder.fit_transform(data_categorical)\n",
    "\n",
    "print(f\"The dataset encoded contains {data_encoded.shape[1]} features\")\n",
    "print(data_encoded[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "model = make_pipeline(OneHotEncoder(handle_unknown='ignore'), LinearSVR())\n",
    "score = cross_val_score(model, data_categorical, target)\n",
    "print(f\"The R2 score is: {score.mean():.2f} +- {score.std():.2f}\")\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn.linear_model import RidgeCV\n",
    "\n",
    "binary_encoding_columns = ['MARR', 'SEX', 'SOUTH', 'UNION']\n",
    "one_hot_encoding_columns = ['OCCUPATION', 'SECTOR', 'RACE']\n",
    "scaling_columns = ['AGE', 'EDUCATION', 'EXPERIENCE']\n",
    "\n",
    "preprocessor = make_column_transformer(\n",
    "    (OrdinalEncoder(), binary_encoding_columns),\n",
    "    (OneHotEncoder(handle_unknown='ignore'), one_hot_encoding_columns),\n",
    "    (StandardScaler(), scaling_columns)\n",
    ")\n",
    "model = make_pipeline(preprocessor, RidgeCV())\n",
    "score = cross_val_score(model, data, target)\n",
    "print(f\"The R2 score is: {score.mean():.2f} +- {score.std():.2f}\")\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "encoding": "# -*- coding: utf-8 -*-",
   "formats": "notebooks//ipynb,markdown_files//md,python_scripts//py:percent"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
